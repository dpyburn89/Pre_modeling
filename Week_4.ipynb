{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpyburn89/Pre_modeling/blob/main/Week_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ee4edf",
      "metadata": {
        "id": "a1ee4edf"
      },
      "source": [
        "# Predictive Modeling - Week 4\n",
        "## Lecture Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48ecd02",
      "metadata": {
        "id": "d48ecd02"
      },
      "outputs": [],
      "source": [
        "%cd C:\\Users\\JamzM\\OneDrive\\Documents\\Teaching\\2022 Fall\\Predictive Modeling"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b78wSBJjW54p"
      },
      "id": "b78wSBJjW54p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing Values\n",
        "\n",
        "You have the option to drop rows or columns that have missing values from your data\n",
        "Impute Missing Values - fill in methods\n",
        "  - Fill with a constant value, such as 0\n",
        "  -Fill FORWARD or BACKWARD\n",
        "  -Interpolate (this is good for sime series data)\n",
        "  -Fill with descriptive statistics (mean, median, mode)\n",
        "  -Fill with the nearest neighbor\n",
        "\n",
        "You can add indicator variables to identify where the missing values were filled in/imputed. Do this when missing values are actually meaninful to your analysis. Python will add a column with an indicato (0 or 1) to track where imputed values were added"
      ],
      "metadata": {
        "id": "83T2rn7wW6hQ"
      },
      "id": "83T2rn7wW6hQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bccc558c",
      "metadata": {
        "scrolled": true,
        "id": "bccc558c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7e57b41e-462e-4557-de59-313b25592843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Yield  BiologicalMaterial01  BiologicalMaterial02  BiologicalMaterial03  \\\n",
              "0  38.00                  6.25                 49.58                 56.97   \n",
              "1  42.44                  8.01                 60.97                 67.48   \n",
              "2  42.03                  8.01                 60.97                 67.48   \n",
              "3  41.42                  8.01                 60.97                 67.48   \n",
              "4  42.49                  7.47                 63.33                 72.25   \n",
              "\n",
              "   BiologicalMaterial04  BiologicalMaterial05  BiologicalMaterial06  \\\n",
              "0                 12.74                 19.51                 43.73   \n",
              "1                 14.65                 19.36                 53.14   \n",
              "2                 14.65                 19.36                 53.14   \n",
              "3                 14.65                 19.36                 53.14   \n",
              "4                 14.02                 17.91                 54.66   \n",
              "\n",
              "   BiologicalMaterial07  BiologicalMaterial08  BiologicalMaterial09  ...  \\\n",
              "0                 100.0                 16.66                 11.44  ...   \n",
              "1                 100.0                 19.04                 12.55  ...   \n",
              "2                 100.0                 19.04                 12.55  ...   \n",
              "3                 100.0                 19.04                 12.55  ...   \n",
              "4                 100.0                 18.22                 12.80  ...   \n",
              "\n",
              "   ManufacturingProcess36  ManufacturingProcess37  ManufacturingProcess38  \\\n",
              "0                   0.019                     0.5                       3   \n",
              "1                   0.019                     2.0                       2   \n",
              "2                   0.018                     0.7                       2   \n",
              "3                   0.018                     1.2                       2   \n",
              "4                   0.017                     0.2                       2   \n",
              "\n",
              "   ManufacturingProcess39  ManufacturingProcess40  ManufacturingProcess41  \\\n",
              "0                     7.2                     NaN                     NaN   \n",
              "1                     7.2                     0.1                    0.15   \n",
              "2                     7.2                     0.0                    0.00   \n",
              "3                     7.2                     0.0                    0.00   \n",
              "4                     7.3                     0.0                    0.00   \n",
              "\n",
              "   ManufacturingProcess42  ManufacturingProcess43  ManufacturingProcess44  \\\n",
              "0                    11.6                     3.0                     1.8   \n",
              "1                    11.1                     0.9                     1.9   \n",
              "2                    12.0                     1.0                     1.8   \n",
              "3                    10.6                     1.1                     1.8   \n",
              "4                    11.0                     1.1                     1.7   \n",
              "\n",
              "   ManufacturingProcess45  \n",
              "0                     2.4  \n",
              "1                     2.2  \n",
              "2                     2.3  \n",
              "3                     2.1  \n",
              "4                     2.1  \n",
              "\n",
              "[5 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32d96143-e9ba-4ab7-97b4-6b7580671003\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yield</th>\n",
              "      <th>BiologicalMaterial01</th>\n",
              "      <th>BiologicalMaterial02</th>\n",
              "      <th>BiologicalMaterial03</th>\n",
              "      <th>BiologicalMaterial04</th>\n",
              "      <th>BiologicalMaterial05</th>\n",
              "      <th>BiologicalMaterial06</th>\n",
              "      <th>BiologicalMaterial07</th>\n",
              "      <th>BiologicalMaterial08</th>\n",
              "      <th>BiologicalMaterial09</th>\n",
              "      <th>...</th>\n",
              "      <th>ManufacturingProcess36</th>\n",
              "      <th>ManufacturingProcess37</th>\n",
              "      <th>ManufacturingProcess38</th>\n",
              "      <th>ManufacturingProcess39</th>\n",
              "      <th>ManufacturingProcess40</th>\n",
              "      <th>ManufacturingProcess41</th>\n",
              "      <th>ManufacturingProcess42</th>\n",
              "      <th>ManufacturingProcess43</th>\n",
              "      <th>ManufacturingProcess44</th>\n",
              "      <th>ManufacturingProcess45</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38.00</td>\n",
              "      <td>6.25</td>\n",
              "      <td>49.58</td>\n",
              "      <td>56.97</td>\n",
              "      <td>12.74</td>\n",
              "      <td>19.51</td>\n",
              "      <td>43.73</td>\n",
              "      <td>100.0</td>\n",
              "      <td>16.66</td>\n",
              "      <td>11.44</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>7.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42.44</td>\n",
              "      <td>8.01</td>\n",
              "      <td>60.97</td>\n",
              "      <td>67.48</td>\n",
              "      <td>14.65</td>\n",
              "      <td>19.36</td>\n",
              "      <td>53.14</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.04</td>\n",
              "      <td>12.55</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>11.1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42.03</td>\n",
              "      <td>8.01</td>\n",
              "      <td>60.97</td>\n",
              "      <td>67.48</td>\n",
              "      <td>14.65</td>\n",
              "      <td>19.36</td>\n",
              "      <td>53.14</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.04</td>\n",
              "      <td>12.55</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.7</td>\n",
              "      <td>2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41.42</td>\n",
              "      <td>8.01</td>\n",
              "      <td>60.97</td>\n",
              "      <td>67.48</td>\n",
              "      <td>14.65</td>\n",
              "      <td>19.36</td>\n",
              "      <td>53.14</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.04</td>\n",
              "      <td>12.55</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.6</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42.49</td>\n",
              "      <td>7.47</td>\n",
              "      <td>63.33</td>\n",
              "      <td>72.25</td>\n",
              "      <td>14.02</td>\n",
              "      <td>17.91</td>\n",
              "      <td>54.66</td>\n",
              "      <td>100.0</td>\n",
              "      <td>18.22</td>\n",
              "      <td>12.80</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>7.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 58 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32d96143-e9ba-4ab7-97b4-6b7580671003')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32d96143-e9ba-4ab7-97b4-6b7580671003 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32d96143-e9ba-4ab7-97b4-6b7580671003');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Predictive Modeling/ChemicalManufacturingProcess.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_YpJCMJ5Mlb",
        "outputId": "82db4891-6c8f-46fd-b70e-1e8b38222114"
      },
      "id": "L_YpJCMJ5Mlb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6cbfc58",
      "metadata": {
        "id": "b6cbfc58"
      },
      "source": [
        "\"ChemicalManufacturingProcess {AppliedPredictiveModeling}\tR Documentation\n",
        "\n",
        "\n",
        "Chemical Manufacturing Process Data\n",
        "Description\n",
        "\n",
        "This data set contains information about a chemical manufacturing process, in which the goal is to understand the relationship between the process and the resulting final product yield. Raw material in this process is put through a sequence of 27 steps to generate the final pharmaceutical product. The starting material is generated from a biological unit and has a range of quality and characteristics. The objective in this project was to develop a model to predict percent yield of the manufacturing process. The data set consisted of 177 samples of biological material for which 57 characteristics were measured. Of the 57 characteristics, there were 12 measurements of the biological starting material, and 45 measurements of the manufacturing process. The process variables included measurements such as temperature, drying time, washing time, and concentrations of by–products at various steps. Some of the process measurements can be controlled, while others are observed. Predictors are continuous, count, categorical; some are correlated, and some contain missing values. Samples are not independent because sets of samples come from the same batch of biological starting material.\n",
        "\n",
        "Value\n",
        "\n",
        "ChemicalManufacturingProcess: a data frame with columns for the outcome (Yield) and the predictors (BiologicalMaterial01 though BiologicalMaterial12 and ManufacturingProcess01 though ManufacturingProcess45\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "998bc920",
      "metadata": {
        "id": "998bc920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6799ba-0b58-4f37-d43f-594b82ea73cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(176, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f3e4adc",
      "metadata": {
        "scrolled": true,
        "id": "1f3e4adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "764bd054-933e-43bd-ec00-699d76ca9185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yield                     float64\n",
              "BiologicalMaterial01      float64\n",
              "BiologicalMaterial02      float64\n",
              "BiologicalMaterial03      float64\n",
              "BiologicalMaterial04      float64\n",
              "BiologicalMaterial05      float64\n",
              "BiologicalMaterial06      float64\n",
              "BiologicalMaterial07      float64\n",
              "BiologicalMaterial08      float64\n",
              "BiologicalMaterial09      float64\n",
              "BiologicalMaterial10      float64\n",
              "BiologicalMaterial11      float64\n",
              "BiologicalMaterial12      float64\n",
              "ManufacturingProcess01    float64\n",
              "ManufacturingProcess02    float64\n",
              "ManufacturingProcess03    float64\n",
              "ManufacturingProcess04    float64\n",
              "ManufacturingProcess05    float64\n",
              "ManufacturingProcess06    float64\n",
              "ManufacturingProcess07    float64\n",
              "ManufacturingProcess08    float64\n",
              "ManufacturingProcess09    float64\n",
              "ManufacturingProcess10    float64\n",
              "ManufacturingProcess11    float64\n",
              "ManufacturingProcess12    float64\n",
              "ManufacturingProcess13    float64\n",
              "ManufacturingProcess14    float64\n",
              "ManufacturingProcess15      int64\n",
              "ManufacturingProcess16      int64\n",
              "ManufacturingProcess17    float64\n",
              "ManufacturingProcess18      int64\n",
              "ManufacturingProcess19      int64\n",
              "ManufacturingProcess20      int64\n",
              "ManufacturingProcess21    float64\n",
              "ManufacturingProcess22    float64\n",
              "ManufacturingProcess23    float64\n",
              "ManufacturingProcess24    float64\n",
              "ManufacturingProcess25    float64\n",
              "ManufacturingProcess26    float64\n",
              "ManufacturingProcess27    float64\n",
              "ManufacturingProcess28    float64\n",
              "ManufacturingProcess29    float64\n",
              "ManufacturingProcess30    float64\n",
              "ManufacturingProcess31    float64\n",
              "ManufacturingProcess32      int64\n",
              "ManufacturingProcess33    float64\n",
              "ManufacturingProcess34    float64\n",
              "ManufacturingProcess35    float64\n",
              "ManufacturingProcess36    float64\n",
              "ManufacturingProcess37    float64\n",
              "ManufacturingProcess38      int64\n",
              "ManufacturingProcess39    float64\n",
              "ManufacturingProcess40    float64\n",
              "ManufacturingProcess41    float64\n",
              "ManufacturingProcess42    float64\n",
              "ManufacturingProcess43    float64\n",
              "ManufacturingProcess44    float64\n",
              "ManufacturingProcess45    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.dtypes\n",
        "# Looking at the types, we can see there are no categorical variables, only floats and ints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13b9a6c",
      "metadata": {
        "scrolled": true,
        "id": "c13b9a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b40cc00-032c-48a2-aa55-3fcb9ba45c57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yield                      0\n",
              "BiologicalMaterial01       0\n",
              "BiologicalMaterial02       0\n",
              "BiologicalMaterial03       0\n",
              "BiologicalMaterial04       0\n",
              "BiologicalMaterial05       0\n",
              "BiologicalMaterial06       0\n",
              "BiologicalMaterial07       0\n",
              "BiologicalMaterial08       0\n",
              "BiologicalMaterial09       0\n",
              "BiologicalMaterial10       0\n",
              "BiologicalMaterial11       0\n",
              "BiologicalMaterial12       0\n",
              "ManufacturingProcess01     1\n",
              "ManufacturingProcess02     3\n",
              "ManufacturingProcess03    15\n",
              "ManufacturingProcess04     1\n",
              "ManufacturingProcess05     1\n",
              "ManufacturingProcess06     2\n",
              "ManufacturingProcess07     1\n",
              "ManufacturingProcess08     1\n",
              "ManufacturingProcess09     0\n",
              "ManufacturingProcess10     9\n",
              "ManufacturingProcess11    10\n",
              "ManufacturingProcess12     1\n",
              "ManufacturingProcess13     0\n",
              "ManufacturingProcess14     1\n",
              "ManufacturingProcess15     0\n",
              "ManufacturingProcess16     0\n",
              "ManufacturingProcess17     0\n",
              "ManufacturingProcess18     0\n",
              "ManufacturingProcess19     0\n",
              "ManufacturingProcess20     0\n",
              "ManufacturingProcess21     0\n",
              "ManufacturingProcess22     1\n",
              "ManufacturingProcess23     1\n",
              "ManufacturingProcess24     1\n",
              "ManufacturingProcess25     5\n",
              "ManufacturingProcess26     5\n",
              "ManufacturingProcess27     5\n",
              "ManufacturingProcess28     5\n",
              "ManufacturingProcess29     5\n",
              "ManufacturingProcess30     5\n",
              "ManufacturingProcess31     5\n",
              "ManufacturingProcess32     0\n",
              "ManufacturingProcess33     5\n",
              "ManufacturingProcess34     5\n",
              "ManufacturingProcess35     5\n",
              "ManufacturingProcess36     5\n",
              "ManufacturingProcess37     0\n",
              "ManufacturingProcess38     0\n",
              "ManufacturingProcess39     0\n",
              "ManufacturingProcess40     1\n",
              "ManufacturingProcess41     1\n",
              "ManufacturingProcess42     0\n",
              "ManufacturingProcess43     0\n",
              "ManufacturingProcess44     0\n",
              "ManufacturingProcess45     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.isna().sum() # Calulate missing values per column, some have more missing values than others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "201885fe",
      "metadata": {
        "scrolled": true,
        "id": "201885fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "f3a2796e-8abb-4dea-9fdb-239ae4b9c147"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Yield  BiologicalMaterial01  BiologicalMaterial02  BiologicalMaterial03  \\\n",
              "0    38.00                  6.25                 49.58                 56.97   \n",
              "1    42.44                  8.01                 60.97                 67.48   \n",
              "2    42.03                  8.01                 60.97                 67.48   \n",
              "3    41.42                  8.01                 60.97                 67.48   \n",
              "4    42.49                  7.47                 63.33                 72.25   \n",
              "..     ...                   ...                   ...                   ...   \n",
              "171  39.66                  6.71                 56.32                 66.19   \n",
              "172  39.68                  6.87                 56.74                 66.61   \n",
              "173  42.23                  7.50                 58.41                 68.30   \n",
              "174  38.48                  7.53                 58.36                 69.25   \n",
              "175  39.49                  7.53                 58.36                 69.25   \n",
              "\n",
              "     BiologicalMaterial04  BiologicalMaterial05  BiologicalMaterial06  \\\n",
              "0                   12.74                 19.51                 43.73   \n",
              "1                   14.65                 19.36                 53.14   \n",
              "2                   14.65                 19.36                 53.14   \n",
              "3                   14.65                 19.36                 53.14   \n",
              "4                   14.02                 17.91                 54.66   \n",
              "..                    ...                   ...                   ...   \n",
              "171                 12.35                 20.02                 50.26   \n",
              "172                 12.55                 20.18                 50.80   \n",
              "173                 13.33                 20.81                 52.96   \n",
              "174                 14.35                 20.57                 51.31   \n",
              "175                 14.35                 20.57                 51.31   \n",
              "\n",
              "     BiologicalMaterial07  BiologicalMaterial08  BiologicalMaterial09  ...  \\\n",
              "0                   100.0                 16.66                 11.44  ...   \n",
              "1                   100.0                 19.04                 12.55  ...   \n",
              "2                   100.0                 19.04                 12.55  ...   \n",
              "3                   100.0                 19.04                 12.55  ...   \n",
              "4                   100.0                 18.22                 12.80  ...   \n",
              "..                    ...                   ...                   ...  ...   \n",
              "171                 100.0                 17.54                 12.50  ...   \n",
              "172                 100.0                 17.48                 12.41  ...   \n",
              "173                 100.0                 17.23                 12.04  ...   \n",
              "174                 100.0                 17.87                 12.77  ...   \n",
              "175                 100.0                 17.87                 12.77  ...   \n",
              "\n",
              "     ManufacturingProcess20  ManufacturingProcess21  ManufacturingProcess32  \\\n",
              "0                      4665                     0.0                     156   \n",
              "1                      4621                     0.0                     169   \n",
              "2                      4621                     0.0                     173   \n",
              "3                      4611                     0.0                     171   \n",
              "4                      4659                    -0.7                     171   \n",
              "..                      ...                     ...                     ...   \n",
              "171                    4612                    -0.4                     156   \n",
              "172                    4584                    -0.5                     158   \n",
              "173                    4538                    -0.3                     167   \n",
              "174                    4592                    -0.5                     156   \n",
              "175                    4607                    -0.9                     160   \n",
              "\n",
              "     ManufacturingProcess37  ManufacturingProcess38  ManufacturingProcess39  \\\n",
              "0                       0.5                       3                     7.2   \n",
              "1                       2.0                       2                     7.2   \n",
              "2                       0.7                       2                     7.2   \n",
              "3                       1.2                       2                     7.2   \n",
              "4                       0.2                       2                     7.3   \n",
              "..                      ...                     ...                     ...   \n",
              "171                     2.3                       0                     0.0   \n",
              "172                     1.0                       0                     0.0   \n",
              "173                     1.3                       0                     0.0   \n",
              "174                     2.3                       0                     0.0   \n",
              "175                     0.9                       0                     0.0   \n",
              "\n",
              "     ManufacturingProcess42  ManufacturingProcess43  ManufacturingProcess44  \\\n",
              "0                      11.6                     3.0                     1.8   \n",
              "1                      11.1                     0.9                     1.9   \n",
              "2                      12.0                     1.0                     1.8   \n",
              "3                      10.6                     1.1                     1.8   \n",
              "4                      11.0                     1.1                     1.7   \n",
              "..                      ...                     ...                     ...   \n",
              "171                     0.0                     0.6                     0.0   \n",
              "172                     0.0                     0.6                     0.0   \n",
              "173                     0.0                     0.6                     0.0   \n",
              "174                     0.0                     0.5                     0.0   \n",
              "175                     0.0                     0.6                     0.0   \n",
              "\n",
              "     ManufacturingProcess45  \n",
              "0                       2.4  \n",
              "1                       2.2  \n",
              "2                       2.3  \n",
              "3                       2.1  \n",
              "4                       2.1  \n",
              "..                      ...  \n",
              "171                     0.0  \n",
              "172                     0.0  \n",
              "173                     0.0  \n",
              "174                     0.0  \n",
              "175                     0.0  \n",
              "\n",
              "[176 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccd8f3f1-f3c7-4187-9234-fc11f4613e10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yield</th>\n",
              "      <th>BiologicalMaterial01</th>\n",
              "      <th>BiologicalMaterial02</th>\n",
              "      <th>BiologicalMaterial03</th>\n",
              "      <th>BiologicalMaterial04</th>\n",
              "      <th>BiologicalMaterial05</th>\n",
              "      <th>BiologicalMaterial06</th>\n",
              "      <th>BiologicalMaterial07</th>\n",
              "      <th>BiologicalMaterial08</th>\n",
              "      <th>BiologicalMaterial09</th>\n",
              "      <th>...</th>\n",
              "      <th>ManufacturingProcess20</th>\n",
              "      <th>ManufacturingProcess21</th>\n",
              "      <th>ManufacturingProcess32</th>\n",
              "      <th>ManufacturingProcess37</th>\n",
              "      <th>ManufacturingProcess38</th>\n",
              "      <th>ManufacturingProcess39</th>\n",
              "      <th>ManufacturingProcess42</th>\n",
              "      <th>ManufacturingProcess43</th>\n",
              "      <th>ManufacturingProcess44</th>\n",
              "      <th>ManufacturingProcess45</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38.00</td>\n",
              "      <td>6.25</td>\n",
              "      <td>49.58</td>\n",
              "      <td>56.97</td>\n",
              "      <td>12.74</td>\n",
              "      <td>19.51</td>\n",
              "      <td>43.73</td>\n",
              "      <td>100.0</td>\n",
              "      <td>16.66</td>\n",
              "      <td>11.44</td>\n",
              "      <td>...</td>\n",
              "      <td>4665</td>\n",
              "      <td>0.0</td>\n",
              "      <td>156</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>7.2</td>\n",
              "      <td>11.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42.44</td>\n",
              "      <td>8.01</td>\n",
              "      <td>60.97</td>\n",
              "      <td>67.48</td>\n",
              "      <td>14.65</td>\n",
              "      <td>19.36</td>\n",
              "      <td>53.14</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.04</td>\n",
              "      <td>12.55</td>\n",
              "      <td>...</td>\n",
              "      <td>4621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>169</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>11.1</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42.03</td>\n",
              "      <td>8.01</td>\n",
              "      <td>60.97</td>\n",
              "      <td>67.48</td>\n",
              "      <td>14.65</td>\n",
              "      <td>19.36</td>\n",
              "      <td>53.14</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.04</td>\n",
              "      <td>12.55</td>\n",
              "      <td>...</td>\n",
              "      <td>4621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>173</td>\n",
              "      <td>0.7</td>\n",
              "      <td>2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41.42</td>\n",
              "      <td>8.01</td>\n",
              "      <td>60.97</td>\n",
              "      <td>67.48</td>\n",
              "      <td>14.65</td>\n",
              "      <td>19.36</td>\n",
              "      <td>53.14</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.04</td>\n",
              "      <td>12.55</td>\n",
              "      <td>...</td>\n",
              "      <td>4611</td>\n",
              "      <td>0.0</td>\n",
              "      <td>171</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>10.6</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42.49</td>\n",
              "      <td>7.47</td>\n",
              "      <td>63.33</td>\n",
              "      <td>72.25</td>\n",
              "      <td>14.02</td>\n",
              "      <td>17.91</td>\n",
              "      <td>54.66</td>\n",
              "      <td>100.0</td>\n",
              "      <td>18.22</td>\n",
              "      <td>12.80</td>\n",
              "      <td>...</td>\n",
              "      <td>4659</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>171</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>7.3</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>39.66</td>\n",
              "      <td>6.71</td>\n",
              "      <td>56.32</td>\n",
              "      <td>66.19</td>\n",
              "      <td>12.35</td>\n",
              "      <td>20.02</td>\n",
              "      <td>50.26</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17.54</td>\n",
              "      <td>12.50</td>\n",
              "      <td>...</td>\n",
              "      <td>4612</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>156</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>39.68</td>\n",
              "      <td>6.87</td>\n",
              "      <td>56.74</td>\n",
              "      <td>66.61</td>\n",
              "      <td>12.55</td>\n",
              "      <td>20.18</td>\n",
              "      <td>50.80</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17.48</td>\n",
              "      <td>12.41</td>\n",
              "      <td>...</td>\n",
              "      <td>4584</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>158</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>42.23</td>\n",
              "      <td>7.50</td>\n",
              "      <td>58.41</td>\n",
              "      <td>68.30</td>\n",
              "      <td>13.33</td>\n",
              "      <td>20.81</td>\n",
              "      <td>52.96</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17.23</td>\n",
              "      <td>12.04</td>\n",
              "      <td>...</td>\n",
              "      <td>4538</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>167</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>38.48</td>\n",
              "      <td>7.53</td>\n",
              "      <td>58.36</td>\n",
              "      <td>69.25</td>\n",
              "      <td>14.35</td>\n",
              "      <td>20.57</td>\n",
              "      <td>51.31</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17.87</td>\n",
              "      <td>12.77</td>\n",
              "      <td>...</td>\n",
              "      <td>4592</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>156</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>39.49</td>\n",
              "      <td>7.53</td>\n",
              "      <td>58.36</td>\n",
              "      <td>69.25</td>\n",
              "      <td>14.35</td>\n",
              "      <td>20.57</td>\n",
              "      <td>51.31</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17.87</td>\n",
              "      <td>12.77</td>\n",
              "      <td>...</td>\n",
              "      <td>4607</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>160</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccd8f3f1-f3c7-4187-9234-fc11f4613e10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccd8f3f1-f3c7-4187-9234-fc11f4613e10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccd8f3f1-f3c7-4187-9234-fc11f4613e10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#data.dropna(axis=0) # Using AXIS=0 delets ROWS of data\n",
        "data.dropna(axis=1) # Using AXIS=1 delete entire columns if there is a missing value in the column\n",
        "\n",
        "# We can see from above that there is missing values in the dataset. We want to come up with a method to remove missing values\n",
        "#  We can drop over rows or columns. If we do that, the data shape changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1481f65b",
      "metadata": {
        "scrolled": true,
        "id": "1481f65b"
      },
      "outputs": [],
      "source": [
        "data['ManufacturingProcess03'].tolist()[0:30] # This first piece of code is to show there are missing values in the ManufacturingProcess03 column\n",
        "#data['ManufacturingProcess03'].fillna(0).tolist()[0:30] # Using FILLNA(0) fills the missing values with a 0\n",
        "#data['ManufacturingProcess03'].fillna(method='ffill').tolist()[0:30] # This is the forward fill method. If NANs at beginning of dataset, those wont change, only values later in the set\n",
        "#data['ManufacturingProcess03'].fillna(method='bfill').tolist()[0:30] # This is the backward fill, so NANs at beginning of set are filled, but ends are not\n",
        "#data['ManufacturingProcess03'].fillna(data['ManufacturingProcess03'].mean()).tolist()[0:30] # Here we're filling the NANs with the mean of the column\n",
        "#data['ManufacturingProcess03'].fillna(data['ManufacturingProcess03'].median()).tolist()[0:30] # Here we're filling the NANs with the median\n",
        "#data['ManufacturingProcess03'].interpolate().tolist()[0:30] # Nothing happens with the first values because there is nothing to interpolate. The nulls are filled in with the average value\n",
        "# Between the number before and after the NAN. EX: 1.5, NAN, 1.6. The NAN is converted to 1.55"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2430dff",
      "metadata": {
        "scrolled": true,
        "id": "b2430dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2863eb-c56b-4a30-c860-1e22167d2dd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [1.56, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.56, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.59, 0.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [1.56, 0.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [0.  , 1.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.48, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.56, 0.  ],\n",
              "       [1.5 , 0.  ],\n",
              "       [1.5 , 0.  ],\n",
              "       [1.56, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.5 , 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.58, 0.  ],\n",
              "       [1.57, 0.  ],\n",
              "       [1.6 , 0.  ],\n",
              "       [1.51, 0.  ],\n",
              "       [1.51, 0.  ],\n",
              "       [1.49, 0.  ],\n",
              "       [1.5 , 0.  ],\n",
              "       [1.51, 0.  ],\n",
              "       [1.5 , 0.  ],\n",
              "       [1.48, 0.  ],\n",
              "       [1.49, 0.  ],\n",
              "       [1.48, 0.  ],\n",
              "       [1.48, 0.  ],\n",
              "       [1.47, 0.  ],\n",
              "       [1.51, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.5 , 0.  ],\n",
              "       [1.48, 0.  ],\n",
              "       [1.52, 0.  ],\n",
              "       [1.57, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.53, 0.  ],\n",
              "       [1.51, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.6 , 0.  ],\n",
              "       [1.59, 0.  ],\n",
              "       [1.6 , 0.  ],\n",
              "       [1.6 , 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.54, 0.  ],\n",
              "       [1.56, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ],\n",
              "       [1.55, 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# We're using SKLEARN's SIMPLE IMPUTER HERE TO DO TRANSFORMATIONS SIMILAR TO ABOVE\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "#imp = SimpleImputer(strategy='mean', add_indicator=True)\n",
        "#imp = SimpleImputer(strategy='median', add_indicator=True)\n",
        "#imp = SimpleImputer(strategy='most_frequent', add_indicator=True)\n",
        "imp = SimpleImputer(strategy='constant', fill_value=0, add_indicator=True) # This is where we are defining the rules for the imputer (how we will fill null values). We're filling with a 0 and specified an indicator column\n",
        "imp.fit(data.loc[:,['ManufacturingProcess03']]) # We apply the transformation to the dataset using the FIT method\n",
        "imp.transform(data.loc[:,['ManufacturingProcess03']]) # Now we're transforming the dataset\n",
        "\n",
        "# In the array below, when the first value is a 0, the indicator column shows a 1, which tells us that the original value was a NAN/NULL and was changed to the 0 using the imputer\n",
        "\n",
        "# The commented codes above are just different methods for imputing values. Instead of doing a line for FIT and another for TRANSFORM you can do imp.fit_transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "022d1df4",
      "metadata": {
        "id": "022d1df4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb18cbd6-e3e8-4e25-ab5c-1b28097eb849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.25      , 49.58      , 56.97      ,  1.54457493,  1.        ],\n",
              "       [ 8.01      , 60.97      , 67.48      ,  1.54158473,  1.        ],\n",
              "       [ 8.01      , 60.97      , 67.48      ,  1.54158473,  1.        ],\n",
              "       [ 8.01      , 60.97      , 67.48      ,  1.54158473,  1.        ],\n",
              "       [ 7.47      , 63.33      , 72.25      ,  1.53912701,  1.        ],\n",
              "       [ 6.12      , 58.36      , 65.31      ,  1.54161452,  1.        ],\n",
              "       [ 7.48      , 64.47      , 72.41      ,  1.56      ,  0.        ],\n",
              "       [ 6.94      , 63.6       , 72.06      ,  1.55      ,  0.        ],\n",
              "       [ 6.94      , 63.6       , 72.06      ,  1.56      ,  0.        ],\n",
              "       [ 6.94      , 63.6       , 72.06      ,  1.55      ,  0.        ],\n",
              "       [ 7.17      , 61.23      , 70.01      ,  1.55      ,  0.        ],\n",
              "       [ 7.17      , 61.23      , 70.01      ,  1.55      ,  0.        ],\n",
              "       [ 7.17      , 61.23      , 70.01      ,  1.55      ,  0.        ],\n",
              "       [ 7.63      , 60.51      , 69.24      ,  1.59      ,  0.        ],\n",
              "       [ 6.23      , 62.93      , 69.74      ,  1.54008284,  1.        ],\n",
              "       [ 7.13      , 60.3       , 68.18      ,  1.54071624,  1.        ],\n",
              "       [ 7.85      , 58.22      , 66.95      ,  1.54121781,  1.        ],\n",
              "       [ 7.64      , 59.44      , 67.22      ,  1.5412627 ,  1.        ],\n",
              "       [ 7.51      , 59.74      , 67.28      ,  1.54125035,  1.        ],\n",
              "       [ 7.51      , 59.74      , 67.28      ,  1.54125035,  1.        ],\n",
              "       [ 7.51      , 59.74      , 67.28      ,  1.56      ,  0.        ],\n",
              "       [ 7.08      , 61.83      , 70.69      ,  1.53956942,  1.        ],\n",
              "       [ 6.58      , 58.38      , 67.17      ,  1.54068455,  1.        ],\n",
              "       [ 6.27      , 56.23      , 64.98      ,  1.54137791,  1.        ],\n",
              "       [ 8.17      , 63.66      , 73.44      ,  1.54      ,  0.        ],\n",
              "       [ 6.6       , 55.74      , 66.25      ,  1.52      ,  0.        ],\n",
              "       [ 6.9       , 54.26      , 60.99      ,  1.53      ,  0.        ],\n",
              "       [ 6.86      , 55.66      , 63.43      ,  1.54      ,  0.        ],\n",
              "       [ 6.67      , 63.44      , 76.94      ,  1.52      ,  0.        ],\n",
              "       [ 6.53      , 61.68      , 77.15      ,  1.52      ,  0.        ],\n",
              "       [ 6.89      , 61.54      , 76.07      ,  1.54      ,  0.        ],\n",
              "       [ 7.13      , 61.39      , 74.1       ,  1.53      ,  0.        ],\n",
              "       [ 6.84      , 61.46      , 73.91      ,  1.52      ,  0.        ],\n",
              "       [ 5.17      , 61.17      , 76.39      ,  1.52      ,  0.        ],\n",
              "       [ 7.01      , 61.3       , 72.71      ,  1.53      ,  0.        ],\n",
              "       [ 6.3       , 57.04      , 70.03      ,  1.53      ,  0.        ],\n",
              "       [ 5.32      , 59.14      , 71.05      ,  1.53      ,  0.        ],\n",
              "       [ 5.32      , 59.14      , 71.05      ,  1.52      ,  0.        ],\n",
              "       [ 5.32      , 59.14      , 71.05      ,  1.54      ,  0.        ],\n",
              "       [ 5.71      , 57.68      , 69.37      ,  1.52      ,  0.        ],\n",
              "       [ 6.6       , 58.8       , 71.17      ,  1.52      ,  0.        ],\n",
              "       [ 6.76      , 55.42      , 69.8       ,  1.48      ,  0.        ],\n",
              "       [ 6.76      , 55.42      , 69.8       ,  1.53      ,  0.        ],\n",
              "       [ 6.76      , 55.42      , 69.8       ,  1.55      ,  0.        ],\n",
              "       [ 6.77      , 58.76      , 72.74      ,  1.56      ,  0.        ],\n",
              "       [ 6.95      , 60.31      , 73.97      ,  1.5       ,  0.        ],\n",
              "       [ 6.95      , 60.31      , 73.97      ,  1.5       ,  0.        ],\n",
              "       [ 6.95      , 60.31      , 73.97      ,  1.56      ,  0.        ],\n",
              "       [ 7.97      , 64.75      , 74.1       ,  1.52      ,  0.        ],\n",
              "       [ 6.94      , 57.02      , 69.51      ,  1.52      ,  0.        ],\n",
              "       [ 6.94      , 57.02      , 69.51      ,  1.53      ,  0.        ],\n",
              "       [ 6.94      , 57.02      , 69.51      ,  1.54      ,  0.        ],\n",
              "       [ 7.56      , 61.62      , 72.17      ,  1.54      ,  0.        ],\n",
              "       [ 6.87      , 57.33      , 71.52      ,  1.54      ,  0.        ],\n",
              "       [ 6.87      , 57.33      , 71.52      ,  1.54      ,  0.        ],\n",
              "       [ 6.87      , 57.33      , 71.52      ,  1.52      ,  0.        ],\n",
              "       [ 6.65      , 55.61      , 68.93      ,  1.5       ,  0.        ],\n",
              "       [ 6.65      , 55.61      , 68.93      ,  1.52      ,  0.        ],\n",
              "       [ 6.65      , 55.61      , 68.93      ,  1.58      ,  0.        ],\n",
              "       [ 6.72      , 57.24      , 71.27      ,  1.57      ,  0.        ],\n",
              "       [ 6.57      , 55.93      , 69.48      ,  1.6       ,  0.        ],\n",
              "       [ 6.16      , 54.67      , 66.95      ,  1.51      ,  0.        ],\n",
              "       [ 6.16      , 54.67      , 66.95      ,  1.51      ,  0.        ],\n",
              "       [ 6.16      , 54.67      , 66.95      ,  1.49      ,  0.        ],\n",
              "       [ 6.37      , 52.67      , 64.34      ,  1.5       ,  0.        ],\n",
              "       [ 6.37      , 52.67      , 64.34      ,  1.51      ,  0.        ],\n",
              "       [ 6.37      , 52.67      , 64.34      ,  1.5       ,  0.        ],\n",
              "       [ 6.31      , 54.42      , 66.13      ,  1.48      ,  0.        ],\n",
              "       [ 6.27      , 53.51      , 66.52      ,  1.49      ,  0.        ],\n",
              "       [ 6.27      , 53.51      , 66.52      ,  1.48      ,  0.        ],\n",
              "       [ 6.27      , 53.51      , 66.52      ,  1.48      ,  0.        ],\n",
              "       [ 6.58      , 52.5       , 63.29      ,  1.47      ,  0.        ],\n",
              "       [ 6.45      , 53.18      , 64.98      ,  1.51      ,  0.        ],\n",
              "       [ 6.39      , 58.85      , 73.45      ,  1.55      ,  0.        ],\n",
              "       [ 6.39      , 58.85      , 73.45      ,  1.54      ,  0.        ],\n",
              "       [ 6.39      , 58.85      , 73.45      ,  1.54      ,  0.        ],\n",
              "       [ 6.35      , 56.93      , 70.87      ,  1.55      ,  0.        ],\n",
              "       [ 6.17      , 53.8       , 65.53      ,  1.55      ,  0.        ],\n",
              "       [ 6.97      , 58.18      , 71.85      ,  1.55      ,  0.        ],\n",
              "       [ 6.97      , 58.18      , 71.85      ,  1.52      ,  0.        ],\n",
              "       [ 6.97      , 58.18      , 71.85      ,  1.53      ,  0.        ],\n",
              "       [ 8.81      , 63.99      , 78.25      ,  1.55      ,  0.        ],\n",
              "       [ 6.8       , 57.21      , 70.34      ,  1.55      ,  0.        ],\n",
              "       [ 6.8       , 57.21      , 70.34      ,  1.55      ,  0.        ],\n",
              "       [ 6.8       , 57.21      , 70.34      ,  1.54      ,  0.        ],\n",
              "       [ 6.3       , 51.96      , 64.07      ,  1.55      ,  0.        ],\n",
              "       [ 6.3       , 51.96      , 64.07      ,  1.55      ,  0.        ],\n",
              "       [ 6.3       , 51.96      , 64.07      ,  1.55      ,  0.        ],\n",
              "       [ 6.45      , 55.09      , 69.18      ,  1.54      ,  0.        ],\n",
              "       [ 6.45      , 55.09      , 69.18      ,  1.55      ,  0.        ],\n",
              "       [ 6.45      , 55.09      , 69.18      ,  1.55      ,  0.        ],\n",
              "       [ 6.28      , 54.33      , 68.3       ,  1.54      ,  0.        ],\n",
              "       [ 7.33      , 56.87      , 70.17      ,  1.54      ,  0.        ],\n",
              "       [ 7.22      , 57.32      , 71.02      ,  1.55      ,  0.        ],\n",
              "       [ 6.19      , 53.59      , 66.4       ,  1.53      ,  0.        ],\n",
              "       [ 5.98      , 54.1       , 66.5       ,  1.53      ,  0.        ],\n",
              "       [ 5.98      , 54.1       , 66.5       ,  1.54      ,  0.        ],\n",
              "       [ 5.98      , 54.1       , 66.5       ,  1.55      ,  0.        ],\n",
              "       [ 5.85      , 51.75      , 64.02      ,  1.54      ,  0.        ],\n",
              "       [ 5.85      , 51.75      , 64.02      ,  1.55      ,  0.        ],\n",
              "       [ 5.85      , 51.75      , 64.02      ,  1.53      ,  0.        ],\n",
              "       [ 6.01      , 51.83      , 63.8       ,  1.54      ,  0.        ],\n",
              "       [ 5.89      , 51.28      , 64.04      ,  1.55      ,  0.        ],\n",
              "       [ 5.9       , 51.44      , 63.61      ,  1.55      ,  0.        ],\n",
              "       [ 5.9       , 51.44      , 63.61      ,  1.55      ,  0.        ],\n",
              "       [ 5.9       , 51.44      , 63.61      ,  1.55      ,  0.        ],\n",
              "       [ 5.79      , 53.96      , 66.53      ,  1.54      ,  0.        ],\n",
              "       [ 5.79      , 53.96      , 66.53      ,  1.5       ,  0.        ],\n",
              "       [ 5.79      , 53.96      , 66.53      ,  1.48      ,  0.        ],\n",
              "       [ 5.94      , 51.27      , 63.54      ,  1.52      ,  0.        ],\n",
              "       [ 6.4       , 58.73      , 71.51      ,  1.57      ,  0.        ],\n",
              "       [ 6.4       , 58.73      , 71.51      ,  1.54      ,  0.        ],\n",
              "       [ 6.4       , 58.73      , 71.51      ,  1.53      ,  0.        ],\n",
              "       [ 6.1       , 56.36      , 69.52      ,  1.51      ,  0.        ],\n",
              "       [ 5.78      , 53.7       , 67.22      ,  1.55      ,  0.        ],\n",
              "       [ 6.15      , 53.06      , 70.29      ,  1.54      ,  0.        ],\n",
              "       [ 6.4       , 52.62      , 72.39      ,  1.55      ,  0.        ],\n",
              "       [ 5.6       , 51.45      , 63.44      ,  1.55      ,  0.        ],\n",
              "       [ 5.6       , 51.45      , 63.44      ,  1.54      ,  0.        ],\n",
              "       [ 5.6       , 51.45      , 63.44      ,  1.55      ,  0.        ],\n",
              "       [ 5.43      , 49.1       , 62.08      ,  1.55      ,  0.        ],\n",
              "       [ 6.02      , 50.01      , 60.82      ,  1.55      ,  0.        ],\n",
              "       [ 6.03      , 52.58      , 65.05      ,  1.55      ,  0.        ],\n",
              "       [ 6.08      , 52.89      , 66.72      ,  1.55      ,  0.        ],\n",
              "       [ 5.76      , 52.73      , 63.88      ,  1.54      ,  0.        ],\n",
              "       [ 5.79      , 52.7       , 64.33      ,  1.55      ,  0.        ],\n",
              "       [ 6.23      , 52.95      , 66.71      ,  1.54      ,  0.        ],\n",
              "       [ 6.23      , 52.95      , 66.71      ,  1.55      ,  0.        ],\n",
              "       [ 6.23      , 52.95      , 66.71      ,  1.54      ,  0.        ],\n",
              "       [ 6.26      , 55.94      , 69.22      ,  1.55      ,  0.        ],\n",
              "       [ 6.26      , 55.94      , 69.22      ,  1.55      ,  0.        ],\n",
              "       [ 6.26      , 55.94      , 69.22      ,  1.54      ,  0.        ],\n",
              "       [ 6.36      , 53.18      , 66.57      ,  1.55      ,  0.        ],\n",
              "       [ 6.72      , 53.85      , 67.1       ,  1.55      ,  0.        ],\n",
              "       [ 5.18      , 48.6       , 61.04      ,  1.54      ,  0.        ],\n",
              "       [ 5.18      , 48.6       , 61.04      ,  1.55      ,  0.        ],\n",
              "       [ 5.18      , 48.6       , 61.04      ,  1.55      ,  0.        ],\n",
              "       [ 6.29      , 50.64      , 63.92      ,  1.55      ,  0.        ],\n",
              "       [ 6.1       , 50.6       , 63.37      ,  1.55      ,  0.        ],\n",
              "       [ 5.3       , 46.87      , 57.56      ,  1.55      ,  0.        ],\n",
              "       [ 5.83      , 50.17      , 63.11      ,  1.54      ,  0.        ],\n",
              "       [ 6.25      , 54.57      , 67.56      ,  1.55      ,  0.        ],\n",
              "       [ 6.25      , 54.57      , 67.56      ,  1.54      ,  0.        ],\n",
              "       [ 6.25      , 54.57      , 67.56      ,  1.55      ,  0.        ],\n",
              "       [ 6.        , 53.29      , 65.5       ,  1.55      ,  0.        ],\n",
              "       [ 6.        , 53.29      , 65.5       ,  1.54      ,  0.        ],\n",
              "       [ 6.        , 53.29      , 65.5       ,  1.55      ,  0.        ],\n",
              "       [ 5.49      , 48.03      , 58.99      ,  1.54      ,  0.        ],\n",
              "       [ 5.3       , 46.87      , 57.56      ,  1.54      ,  0.        ],\n",
              "       [ 5.54      , 52.48      , 64.98      ,  1.54      ,  0.        ],\n",
              "       [ 5.54      , 52.29      , 64.61      ,  1.54      ,  0.        ],\n",
              "       [ 6.25      , 52.68      , 65.12      ,  1.6       ,  0.        ],\n",
              "       [ 6.25      , 52.68      , 65.12      ,  1.59      ,  0.        ],\n",
              "       [ 6.25      , 52.68      , 65.12      ,  1.6       ,  0.        ],\n",
              "       [ 6.22      , 52.76      , 65.13      ,  1.6       ,  0.        ],\n",
              "       [ 5.9       , 51.37      , 63.65      ,  1.54      ,  0.        ],\n",
              "       [ 5.9       , 51.37      , 63.65      ,  1.55      ,  0.        ],\n",
              "       [ 5.9       , 51.37      , 63.65      ,  1.55      ,  0.        ],\n",
              "       [ 5.7       , 52.77      , 66.25      ,  1.55      ,  0.        ],\n",
              "       [ 5.7       , 52.77      , 66.25      ,  1.55      ,  0.        ],\n",
              "       [ 5.7       , 52.77      , 66.25      ,  1.54      ,  0.        ],\n",
              "       [ 5.97      , 53.13      , 66.58      ,  1.54      ,  0.        ],\n",
              "       [ 6.39      , 53.72      , 67.13      ,  1.55      ,  0.        ],\n",
              "       [ 5.36      , 53.39      , 65.3       ,  1.55      ,  0.        ],\n",
              "       [ 5.27      , 52.45      , 64.09      ,  1.55      ,  0.        ],\n",
              "       [ 4.58      , 49.56      , 61.08      ,  1.55      ,  0.        ],\n",
              "       [ 4.58      , 49.56      , 61.08      ,  1.55      ,  0.        ],\n",
              "       [ 4.58      , 49.56      , 61.08      ,  1.55      ,  0.        ],\n",
              "       [ 7.7       , 62.92      , 75.91      ,  1.55      ,  0.        ],\n",
              "       [ 6.39      , 59.1       , 71.04      ,  1.55      ,  0.        ],\n",
              "       [ 6.63      , 59.81      , 71.94      ,  1.54      ,  0.        ],\n",
              "       [ 6.71      , 56.32      , 66.19      ,  1.54      ,  0.        ],\n",
              "       [ 6.87      , 56.74      , 66.61      ,  1.56      ,  0.        ],\n",
              "       [ 7.5       , 58.41      , 68.3       ,  1.55      ,  0.        ],\n",
              "       [ 7.53      , 58.36      , 69.25      ,  1.55      ,  0.        ],\n",
              "       [ 7.53      , 58.36      , 69.25      ,  1.55      ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import numpy as np\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa -- this is an iterative imputer, it uses a stats algorithm to fill in the missing values based on the other columns\n",
        "# now you can import normally from sklearn.impute\n",
        "from sklearn.impute import IterativeImputer\n",
        "imp = IterativeImputer(add_indicator=True)\n",
        "imp.fit(data.loc[:,['BiologicalMaterial01', 'BiologicalMaterial02', 'BiologicalMaterial03', 'ManufacturingProcess03']])\n",
        "imp.transform(data.loc[:,['BiologicalMaterial01', 'BiologicalMaterial02', 'BiologicalMaterial03', 'ManufacturingProcess03']])\n",
        "\n",
        "# Not all columns have an indicator column next to them, that's because the column did not contain any NULL values. The last column showing is the imputer because the ManProc03 has missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1a7562",
      "metadata": {
        "scrolled": true,
        "id": "0d1a7562"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer # This is when you want to use the K Nearest Neighbor algorithm to fill the data\n",
        "imp = KNNImputer(add_indicator=True)\n",
        "imp.fit(data.loc[:,['BiologicalMaterial01', 'BiologicalMaterial02', 'BiologicalMaterial03', 'ManufacturingProcess01', 'ManufacturingProcess02', 'ManufacturingProcess03']])\n",
        "imp.transform(data.loc[:,['BiologicalMaterial01', 'BiologicalMaterial02', 'BiologicalMaterial03', 'ManufacturingProcess01', 'ManufacturingProcess02', 'ManufacturingProcess03']])\n",
        "#pd.DataFrame(imp.transform(data.loc[:,['BiologicalMaterial01', 'BiologicalMaterial02', 'BiologicalMaterial03', 'ManufacturingProcess01', 'ManufacturingProcess02', 'ManufacturingProcess03']]),\n",
        "#            columns=imp.get_feature_names_out())\n",
        "\n",
        "# You want to use the dataframe code from above. Otherwise the code will only produce an array and you want get the column names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab3024b1",
      "metadata": {
        "id": "ab3024b1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import MissingIndicator\n",
        "#ind = MissingIndicator()\n",
        "ind = MissingIndicator()\n",
        "ind.fit(data.loc[:,['ManufacturingProcess03']])\n",
        "ind.transform(data.loc[:,['ManufacturingProcess03']])\n",
        "\n",
        "# Since the ind is a missing indicator, it returns a BOOLEAN value (true, false). You can use the pd.dataframe code form above to put it into  a dataframe to read more easily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8b91ec",
      "metadata": {
        "id": "9c8b91ec"
      },
      "outputs": [],
      "source": [
        "# Use sklearn to create train and test data sets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('ChemicalManufacturingProcess.csv')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = data['Yield']\n",
        "X = data.copy().drop(columns=['Yield']) # Standard Train Test Split, we're predicting Yield, and using all other columns to predict it. Which is why there is the DROP function\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "997cc768",
      "metadata": {
        "scrolled": true,
        "id": "997cc768"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(regr.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(regr.score(X_test, y_test)))\n",
        "\n",
        "##### THIS CODE PRODUCES AN ERROR -- MISSING VALUES IN THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1188add",
      "metadata": {
        "id": "a1188add"
      },
      "outputs": [],
      "source": [
        "### Because we have missing values, we need to do some data transformations using the imputer and or column transfers\n",
        "\n",
        "import numpy as np\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "# now you can import normally from sklearn.impute\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# Update X_train with data from the imputer\n",
        "imp = IterativeImputer(add_indicator=True) # We're setting up the rule for the imputer - we're adding the column indicator, no method to fill because it's the ITERATIVE IMPUTER\n",
        "imp.fit(X_train) # We're fitting it on the traning set (DO NOT FIT ON TEST SET)\n",
        "orig_columns = X_train.columns # We're also preserving the original columns\n",
        "X_train = pd.DataFrame(imp.transform(X_train), columns=imp.get_feature_names_out()) # We're updating the original X_train with the filled in values and will pass them through the column transfer\n",
        "\n",
        "# Update original columns of X_train using the StandardScaler\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), orig_columns), # Here we're scaling the values over the original data columns we preserved earlier\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train = pd.DataFrame(ct.fit_transform(X_train), columns=imp.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef51ae8",
      "metadata": {
        "id": "eef51ae8"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa40e91",
      "metadata": {
        "scrolled": true,
        "id": "bfa40e91"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(regr.score(X_train, y_train)))\n",
        "\n",
        "X_test = pd.DataFrame(imp.transform(X_test), columns=imp.get_feature_names_out())\n",
        "X_test = pd.DataFrame(ct.fit_transform(X_test), columns=imp.get_feature_names_out())\n",
        "print(\"Test set score: {:.3f}\".format(regr.score(X_test, y_test)))\n",
        "\n",
        "# The result here was .831 training set score, not bad. The TEST score came out to a huge negative number so something is wrong. Colinearity could explain the issue\n",
        "# We could also be overfitting - features in the training set are not generalizing well to the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e1ce592",
      "metadata": {
        "scrolled": false,
        "id": "3e1ce592"
      },
      "outputs": [],
      "source": [
        "# Let's try again with a different train/test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=250) # Changed the random state to give a different result in the split\n",
        "\n",
        "# Update X_train with data from the imputer\n",
        "imp = IterativeImputer(add_indicator=True)\n",
        "imp.fit(X_train)\n",
        "orig_columns = X_train.columns\n",
        "X_train = pd.DataFrame(imp.transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "# Update original columns of X_train using the StandardScaler\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), orig_columns),\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train = pd.DataFrame(ct.fit_transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(regr.score(X_train, y_train)))\n",
        "\n",
        "X_test = pd.DataFrame(imp.transform(X_test), columns=imp.get_feature_names_out())\n",
        "X_test = pd.DataFrame(ct.fit_transform(X_test), columns=imp.get_feature_names_out())\n",
        "print(\"Test set score: {:.3f}\".format(regr.score(X_test, y_test)))\n",
        "\n",
        "# Again we see the model doesn't generalize well since the test score is a large negative number. The amount of predictors we have could be an issue, as could the sample size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08240f6e",
      "metadata": {
        "id": "08240f6e"
      },
      "outputs": [],
      "source": [
        "# Let's try again with Ridge regression\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# Update X_train with data from the imputer\n",
        "imp = IterativeImputer(add_indicator=True)\n",
        "imp.fit(X_train)\n",
        "orig_columns = X_train.columns\n",
        "X_train = pd.DataFrame(imp.transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "# Update original columns of X_train using the StandardScaler\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), orig_columns),\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train = pd.DataFrame(ct.fit_transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.Ridge(alpha=0.01) # You can modify the ALPHA value, in class we adjusted to 100\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(regr.score(X_train, y_train)))\n",
        "\n",
        "X_test = pd.DataFrame(imp.transform(X_test), columns=imp.get_feature_names_out())\n",
        "X_test = pd.DataFrame(ct.fit_transform(X_test), columns=imp.get_feature_names_out())\n",
        "print(\"Test set score: {:.3f}\".format(regr.score(X_test, y_test)))\n",
        "\n",
        "# The ridge regression is better and by making adjustments to the ALPHA level, we can change the results\n",
        "# The goal is to be as accurate as mossible on the test set, once the score starts to go down, stop adjusting the ALPHA level because you've generalized the model\n",
        "\n",
        "# The issue here is that we are adjusting the model based on the TEST set, which leads to bias in your model. This is why we use CROSS-VALIDATION, it prevents leakage to the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f76d86",
      "metadata": {
        "scrolled": false,
        "id": "a3f76d86"
      },
      "outputs": [],
      "source": [
        "# Let's use cross-validation with the training data to evaluate Ridge regression for several values of alpha\n",
        "\n",
        "# we may want to split up the data again, for this exercise we will redo the Train, test split. This is to ensure we have a never before used TEST set\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# Update X_train with data from the imputer\n",
        "imp = IterativeImputer(add_indicator=True)\n",
        "imp.fit(X_train)\n",
        "orig_columns = X_train.columns\n",
        "X_train = pd.DataFrame(imp.transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "# Update original columns of X_train using the StandardScaler\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), orig_columns),\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train = pd.DataFrame(ct.fit_transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "for a in [.01, .1, 1, 10, 100, 1000]: # THIS IS OUR LOOP OF ALPHA VALUES, we're creating a test and will get results for EACH ALPHA \n",
        "    # Create linear regression object\n",
        "    regr = linear_model.Ridge(alpha=a) # The a here will get subbed for the alpha values listed above\n",
        "\n",
        "    # Define k-fold cross validatation\n",
        "    kfold = KFold(n_splits=5) # we're folding the data for testing, 5 is common\n",
        "    \n",
        "    res = cross_validate(regr, X_train, y_train, cv=5, return_train_score=True)\n",
        "    display(res)\n",
        "    summary = cross_val_score(regr, X_train, y_train, cv=kfold)\n",
        "    print(\"Mean cross-validation scores with alpha = {}: {:.3f}\".format(a, summary.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e4a4af",
      "metadata": {
        "scrolled": true,
        "id": "b7e4a4af"
      },
      "outputs": [],
      "source": [
        "# Having used cross-validation to determine ridge regression with alpha=10 generalizes well,\n",
        "# let's train the model on the entire X_train data set and test it with the X_test data set\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.Ridge(alpha=10) # Alpha is set to 10 because that gave the best cross validation score before it started to decrease\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(regr.score(X_train, y_train)))\n",
        "\n",
        "X_test = pd.DataFrame(imp.transform(X_test), columns=imp.get_feature_names_out())\n",
        "X_test = pd.DataFrame(ct.transform(X_test), columns=imp.get_feature_names_out())\n",
        "print(\"Test set score: {:.3f}\".format(regr.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84efe74",
      "metadata": {
        "id": "c84efe74"
      },
      "outputs": [],
      "source": [
        "# Next, let's investigate the coefficients of the ridge regression model\n",
        "\n",
        "coef_dict = {}\n",
        "coef_dict['const'] = regr.intercept_\n",
        "k = 0\n",
        "for i in regr.feature_names_in_:\n",
        "    coef_dict[i] = regr.coef_[k]\n",
        "    k += 1\n",
        "print(coef_dict)\n",
        "\n",
        "# This just shows us the coefficients for each variable, lots of rows, not really useful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18db3ff6",
      "metadata": {
        "id": "18db3ff6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_train_pred = regr.predict(X_train)\n",
        "y_test_pred = regr.predict(X_test)\n",
        "# Simple Linear Regression\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_train_pred, y_train, s=8, alpha=0.5, label='train')\n",
        "plt.scatter(y_test_pred, y_test, s=8, alpha=0.5, c='red', label='test')\n",
        "plt.xlabel('Predicted Yield')\n",
        "plt.ylabel('Actual Yield')\n",
        "plt.title('Scatter Plot')\n",
        "plt.legend()\n",
        "\n",
        "# This plots the targets. We have the training values in blue, test in red. You can see we're not exactly making accurate predictions, but getting close. The slop is at least the same\n",
        "# Between the training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beba73fe",
      "metadata": {
        "id": "beba73fe"
      },
      "outputs": [],
      "source": [
        "# Let's use cross-validation with the training data to evaluate Lasso regression for several values of alpha\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# Update X_train with data from the imputer\n",
        "imp = IterativeImputer(add_indicator=True)\n",
        "imp.fit(X_train)\n",
        "orig_columns = X_train.columns\n",
        "X_train = pd.DataFrame(imp.transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "# Update original columns of X_train using the StandardScaler\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), orig_columns),\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train = pd.DataFrame(ct.fit_transform(X_train), columns=imp.get_feature_names_out())\n",
        "\n",
        "for a in [0.01, 0.05, 0.1, 0.2, 0.3, 0.4]:\n",
        "    # Create linear regression object\n",
        "    regr = linear_model.Lasso(alpha=a)\n",
        "\n",
        "    # Define k-fold cross validatation\n",
        "    kfold = KFold(n_splits=5)\n",
        "    \n",
        "    res = cross_validate(regr, X_train, y_train, cv=5, return_train_score=True)\n",
        "    display(res)\n",
        "    summary = cross_val_score(regr, X_train, y_train, cv=kfold)\n",
        "    print(\"Mean cross-validation scores with alpha = {}: {:.3f}\".format(a, summary.mean()))\n",
        "\n",
        "\n",
        "  # WITH LASSO, the code is pretty much unchanged compared to Ridge, it's just a different method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8af5f4",
      "metadata": {
        "scrolled": false,
        "id": "4e8af5f4"
      },
      "outputs": [],
      "source": [
        "# Having used cross-validation to determine lasso regression with alpha=.05 generalizes well,\n",
        "# let's train the model on the entire X_train data set and test it with the X_test data set\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.Lasso(alpha=.05)\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(regr.score(X_train, y_train)))\n",
        "\n",
        "X_test = pd.DataFrame(imp.transform(X_test), columns=imp.get_feature_names_out())\n",
        "X_test = pd.DataFrame(ct.transform(X_test), columns=imp.get_feature_names_out())\n",
        "print(\"Test set score: {:.3f}\".format(regr.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc217fe3",
      "metadata": {
        "scrolled": false,
        "id": "bc217fe3"
      },
      "outputs": [],
      "source": [
        "# Next, let's investigate the coefficients of the lasso regression model\n",
        "\n",
        "coef_dict = {}\n",
        "coef_dict['const'] = regr.intercept_\n",
        "k = 0\n",
        "for i in regr.feature_names_in_:\n",
        "    coef_dict[i] = regr.coef_[k]\n",
        "    k += 1\n",
        "print(coef_dict)\n",
        "\n",
        "\n",
        "# AGain, this just shows us the coefficient values for all the predictors, not really useful because most coefficients are 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c94c62",
      "metadata": {
        "id": "d4c94c62"
      },
      "outputs": [],
      "source": [
        "nonzero_coef_dict = {}\n",
        "nonzero_coef_dict['const'] = regr.intercept_\n",
        "k = 0\n",
        "for i in regr.feature_names_in_:\n",
        "    if regr.coef_[k] != 0:\n",
        "        nonzero_coef_dict[i] = regr.coef_[k]\n",
        "    k += 1\n",
        "print(nonzero_coef_dict)\n",
        "\n",
        "# This gives us a better look at which coefficients included in the model are having an effect, since they are not 0 as defined by the for loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb8a3ec",
      "metadata": {
        "scrolled": false,
        "id": "3fb8a3ec"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_train_pred = regr.predict(X_train)\n",
        "y_test_pred = regr.predict(X_test)\n",
        "# Simple Linear Regression\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_train_pred, y_train, s=8, alpha=0.5, label='train')\n",
        "plt.scatter(y_test_pred, y_test, s=8, alpha=0.5, c='red', label='test')\n",
        "plt.xlabel('Predicted Yield')\n",
        "plt.ylabel('Actual Yield')\n",
        "plt.title('Scatter Plot')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535a6525",
      "metadata": {
        "scrolled": true,
        "id": "535a6525"
      },
      "outputs": [],
      "source": [
        "# Let's try a similar approach with a Logistic Regression model\n",
        "\n",
        "import pandas as pd\n",
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "# now you can import normally from sklearn.impute\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = pd.read_csv('cars2010.csv')\n",
        "\n",
        "y_train = data['DriveDesc']\n",
        "X_train = data.copy().drop(columns=['DriveDesc'])\n",
        "\n",
        "# Initialize lists of string anf numeric variables\n",
        "str_vars = [] # String variables\n",
        "num_vars = [] # Numeric variables\n",
        "\n",
        "# Loop through data.columns and append the column to the apprpriate str_vars or num_vars\n",
        "# if the conditions are met\n",
        "for i in X_train.columns:\n",
        "    if X_train.dtypes[i] == 'object':\n",
        "        str_vars.append(i) # In this loop, we're saying if the object type is String, put it in the str_vars list we defined above\n",
        "    else:\n",
        "        num_vars.append(i)\n",
        "\n",
        "# Update X_train with data from the imputer\n",
        "ct = make_column_transformer(\n",
        "    (OneHotEncoder(sparse=False), str_vars), # You cannot do regression on strings - so we need to use the ONE HOT ENCODER\n",
        "    (StandardScaler(), num_vars)\n",
        ")\n",
        "ct.fit(X_train)\n",
        "X_train = pd.DataFrame(ct.transform(X_train), columns=ct.get_feature_names_out())\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3200dbc7",
      "metadata": {
        "scrolled": false,
        "id": "3200dbc7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Use cross-validation\n",
        "for i in [0.6, 0.8, 1, 1.2, 1.4, 1.5]:\n",
        "    # Create linear regression object\n",
        "    logr = LogisticRegression(C=i, penalty='l1', solver='liblinear', max_iter=1000)\n",
        "\n",
        "    # Define k-fold cross validatation\n",
        "    kfold = StratifiedKFold(n_splits=5)\n",
        "    \n",
        "    res = cross_validate(logr, X_train, y_train, cv=kfold, return_train_score=True)\n",
        "    display(res)\n",
        "    summary = cross_val_score(logr, X_train, y_train, cv=kfold)\n",
        "    print(\"Mean cross-validation scores with C = {}: {:.3f}\".format(i, summary.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a94a5e9",
      "metadata": {
        "scrolled": true,
        "id": "1a94a5e9"
      },
      "outputs": [],
      "source": [
        "# Having used cross-validation to determine logistic regression with C=1 generalizes well,\n",
        "# let's train the model on the entire X_train data set and test it with the X_test data set\n",
        "\n",
        "# Create logistic regression object\n",
        "logr = LogisticRegression(C=1, penalty='l1', solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Train the model using the training sets\n",
        "logr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(logr.score(X_train, y_train)))\n",
        "\n",
        "# Load and process test data\n",
        "new_data = pd.read_csv('cars2011.csv')\n",
        "\n",
        "y_test = new_data['DriveDesc']\n",
        "X_test = new_data.copy().drop(columns=['DriveDesc'])\n",
        "\n",
        "X_test= pd.DataFrame(ct.transform(X_test), columns=ct.get_feature_names_out())\n",
        "X_test\n",
        "\n",
        "print(\"Test set score: {:.3f}\".format(logr.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652f0245",
      "metadata": {
        "scrolled": true,
        "id": "652f0245"
      },
      "outputs": [],
      "source": [
        "logr.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e76dcf",
      "metadata": {
        "scrolled": true,
        "id": "22e76dcf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_test_pred = logr.predict(X_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_test_pred), display_labels=logr.classes_)\n",
        "disp.plot(xticks_rotation=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b6831cb",
      "metadata": {
        "id": "7b6831cb"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30241b80",
      "metadata": {
        "id": "30241b80"
      },
      "outputs": [],
      "source": [
        "logr.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93fb4e3",
      "metadata": {
        "scrolled": false,
        "id": "a93fb4e3"
      },
      "outputs": [],
      "source": [
        "y_test_pred = logr.predict(X_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_test_pred), display_labels=logr.classes_[[0, 1, 3, 4]])\n",
        "disp.plot(xticks_rotation=90)\n",
        "\n",
        "# Here we're creating the confusion matrix to see how well our model worked. We want to see a diagonal line sloping down from left to right and lighter colors on the slope\n",
        "# That means we predicted accurately"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3594e6c8",
      "metadata": {
        "id": "3594e6c8"
      },
      "source": [
        "## Student Practice Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab11a46",
      "metadata": {
        "id": "dab11a46"
      },
      "source": [
        "\"Soybean {mlbench}\tR Documentation\n",
        "\n",
        "Soybean Database\n",
        "\n",
        "Description\n",
        "\n",
        "There are 19 classes, only the first 15 of which have been used in prior work. The folklore seems to be that the last four classes are unjustified by the data since they have so few examples. There are 35 categorical attributes, some nominal and some ordered. The value “dna” means does not apply. The values for attributes are encoded numerically, with the first value encoded as “0,” the second as “1,” and so forth.\n",
        "\n",
        "Format\n",
        "\n",
        "A data frame with 683 observations on 36 variables. There are 35 categorical attributes, all numerical and a nominal denoting the class.\n",
        "\n",
        "[,1]\tClass\tthe 19 classes\n",
        "\n",
        "[,2]\tdate\tapr(0),may(1),june(2),july(3),aug(4),sept(5),oct(6).\n",
        "\n",
        "[,3]\tplant.stand\tnormal(0),lt-normal(1).\n",
        "\n",
        "[,4]\tprecip\tlt-norm(0),norm(1),gt-norm(2).\n",
        "\n",
        "[,5]\ttemp\tlt-norm(0),norm(1),gt-norm(2).\n",
        "\n",
        "[,6]\thail\tyes(0),no(1).\n",
        "[,7]\tcrop.hist\tdif-lst-yr(0),s-l-y(1),s-l-2-y(2), s-l-7-y(3).\n",
        "\n",
        "[,8]\tarea.dam\tscatter(0),low-area(1),upper-ar(2),whole-field(3).\n",
        "\n",
        "[,9]\tsever\tminor(0),pot-severe(1),severe(2).\n",
        "\n",
        "[,10]\tseed.tmt\tnone(0),fungicide(1),other(2).\n",
        "\n",
        "[,11]\tgerm\t90-100%(0),80-89%(1),lt-80%(2).\n",
        "\n",
        "[,12]\tplant.growth\tnorm(0),abnorm(1).\n",
        "\n",
        "[,13]\tleaves\tnorm(0),abnorm(1).\n",
        "\n",
        "[,14]\tleaf.halo\tabsent(0),yellow-halos(1),no-yellow-halos(2).\n",
        "\n",
        "[,15]\tleaf.marg\tw-s-marg(0),no-w-s-marg(1),dna(2).\n",
        "\n",
        "[,16]\tleaf.size\tlt-1/8(0),gt-1/8(1),dna(2).\n",
        "\n",
        "[,17]\tleaf.shread\tabsent(0),present(1).\n",
        "\n",
        "[,18]\tleaf.malf\tabsent(0),present(1).\n",
        "\n",
        "[,19]\tleaf.mild\tabsent(0),upper-surf(1),lower-surf(2).\n",
        "\n",
        "[,20]\tstem\tnorm(0),abnorm(1).\n",
        "\n",
        "[,21]\tlodging\tyes(0),no(1).\n",
        "\n",
        "[,22]\tstem.cankers\tabsent(0),below-soil(1),above-s(2),ab-sec-nde(3).\n",
        "\n",
        "[,23]\tcanker.lesion\tdna(0),brown(1),dk-brown-blk(2),tan(3).\n",
        "\n",
        "[,24]\tfruiting.bodies\tabsent(0),present(1).\n",
        "\n",
        "[,25]\text.decay\tabsent(0),firm-and-dry(1),watery(2).\n",
        "\n",
        "[,26]\tmycelium\tabsent(0),present(1).\n",
        "\n",
        "[,27]\tint.discolor\tnone(0),brown(1),black(2).\n",
        "\n",
        "[,28]\tsclerotia\tabsent(0),present(1).\n",
        "\n",
        "[,29]\tfruit.pods\tnorm(0),diseased(1),few-present(2),dna(3).\n",
        "\n",
        "[,30]\tfruit.spots\tabsent(0),col(1),br-w/blk-speck(2),distort(3),dna(4).\n",
        "\n",
        "[,31]\tseed\tnorm(0),abnorm(1).\n",
        "\n",
        "[,32]\tmold.growth\tabsent(0),present(1).\n",
        "[,33]\tseed.discolor\tabsent(0),present(1).\n",
        "\n",
        "[,34]\tseed.size\tnorm(0),lt-norm(1).\n",
        "\n",
        "[,35]\tshriveling\tabsent(0),present(1).\n",
        "\n",
        "[,36]\troots\tnorm(0),rotted(1),galls-cysts(2).\n",
        "\n",
        "Source\n",
        "\n",
        "Source: R.S. Michalski and R.L. Chilausky \"Learning by Being Told and Learning from Examples: An Experimental Comparison of the Two Methods of Knowledge Acquisition in the Context of Developing an Expert System for Soybean Disease Diagnosis\", International Journal of Policy Analysis and Information Systems, Vol. 4, No. 2, 1980.\n",
        "\n",
        "Donor: Ming Tan & Jeff Schlimmer (Jeff.Schlimmer%cs.cmu.edu)\n",
        "\n",
        "These data have been taken from the UCI Repository Of Machine Learning Databases at\n",
        "\n",
        "ftp://ftp.ics.uci.edu/pub/machine-learning-databases\n",
        "\n",
        "http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
        "\n",
        "and were converted to R format by Evgenia Dimitriadou.\n",
        "\n",
        "References\n",
        "\n",
        "Tan, M., & Eshelman, L. (1988). Using weighted networks to represent classification knowledge in noisy domains. Proceedings of the Fifth International Conference on Machine Learning (pp. 121-134). Ann Arbor, Michigan: Morgan Kaufmann. – IWN recorded a 97.1% classification accuracy – 290 training and 340 test instances\n",
        "\n",
        "Fisher,D.H. & Schlimmer,J.C. (1988). Concept Simplification and Predictive Accuracy. Proceedings of the Fifth International Conference on Machine Learning (pp. 22-28). Ann Arbor, Michigan: Morgan Kaufmann. – Notes why this database is highly predictable\n",
        "\n",
        "Newman, D.J. & Hettich, S. & Blake, C.L. & Merz, C.J. (1998). UCI Repository of machine learning databases [http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA: University of California, Department of Information and Computer Science.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4575eb5e",
      "metadata": {
        "scrolled": true,
        "id": "4575eb5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6459b1-68e5-4429-a861-898893b98f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class                0\n",
              "date                 1\n",
              "plant.stand         36\n",
              "precip              38\n",
              "temp                30\n",
              "hail               121\n",
              "crop.hist           16\n",
              "area.dam             1\n",
              "sever              121\n",
              "seed.tmt           121\n",
              "germ               112\n",
              "plant.growth        16\n",
              "leaves               0\n",
              "leaf.halo           84\n",
              "leaf.marg           84\n",
              "leaf.size           84\n",
              "leaf.shread        100\n",
              "leaf.malf           84\n",
              "leaf.mild          108\n",
              "stem                16\n",
              "lodging            121\n",
              "stem.cankers        38\n",
              "canker.lesion       38\n",
              "fruiting.bodies    106\n",
              "ext.decay           38\n",
              "mycelium            38\n",
              "int.discolor        38\n",
              "sclerotia           38\n",
              "fruit.pods          84\n",
              "fruit.spots        106\n",
              "seed                92\n",
              "mold.growth         92\n",
              "seed.discolor      106\n",
              "seed.size           92\n",
              "shriveling         106\n",
              "roots               31\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 1\n",
        "\n",
        "# Load Soybean data.\n",
        "# Newman, D.J. & Hettich, S. & Blake, C.L. & Merz, C.J. (1998).\n",
        "# UCI Repository of machine learning databases\n",
        "# [http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:\n",
        "# University of California, Department of Information and\n",
        "# Computer Science.\n",
        "\n",
        "import pandas as pd\n",
        "Soybean = pd.read_csv('Soybean.csv')\n",
        "\n",
        "# Write python code to display the number of missing values in each column\n",
        "\n",
        "Soybean.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20bb64f7",
      "metadata": {
        "scrolled": true,
        "id": "20bb64f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "becb5427-4858-4bef-eb72-c76075976b49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      2.000000\n",
              "1      2.000000\n",
              "2      2.000000\n",
              "3      2.000000\n",
              "4      2.000000\n",
              "         ...   \n",
              "678    1.596899\n",
              "679    1.596899\n",
              "680    1.596899\n",
              "681    1.596899\n",
              "682    1.596899\n",
              "Name: precip, Length: 683, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 2\n",
        "\n",
        "# Use the pandas fillna function to replace missing values in the precip column with the mean value of that column\n",
        "\n",
        "Soybean['precip'].fillna(Soybean['precip'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30cdf99",
      "metadata": {
        "id": "f30cdf99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df071de-a5da-426f-d413-01df12c3f4f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# 3\n",
        "\n",
        "# Use the pandas fillna function to replace missing values in the hail column with the constant value zero\n",
        "Soybean['hail'].fillna(0). tolist()[0:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da08079a",
      "metadata": {
        "scrolled": true,
        "id": "da08079a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b008bb-153a-4207-d60f-8f8da3c3d1de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 4\n",
        "\n",
        "# Use the scikit-learn SimpleImputer function to replace missing values in the temp column with the \n",
        "# mean value of that column\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp = SimpleImputer(strategy='mean', add_indicator=True)\n",
        "imp.fit(Soybean.loc[:, ['temp']])\n",
        "imp.transform(Soybean.loc[:, ['temp']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66f10127",
      "metadata": {
        "id": "66f10127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3fcc92-4a64-4eac-dfb2-fa29190485bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 5\n",
        "\n",
        "# Use the scikit-learn SimpleImputer function to replace missing values in the plant.stand column with the \n",
        "# most frequent value of that column\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp = SimpleImputer(strategy='most_frequent', add_indicator=True)\n",
        "imp.fit(Soybean.loc[:, ['plant.stand']])\n",
        "imp.transform(Soybean.loc[:, ['plant.stand']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91599bac",
      "metadata": {
        "id": "91599bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961117db-b508-4853-adcf-531674c1ae4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [2., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 6\n",
        "\n",
        "# Use the scikit-learn SimpleImputer function to replace missing values in the crop.hist column with the \n",
        "# median value of that column\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imp = SimpleImputer(strategy='median', add_indicator=True)\n",
        "imp.fit(Soybean.loc[:,['crop.hist']])\n",
        "imp.transform(Soybean.loc[:,['crop.hist']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e8ae3b4",
      "metadata": {
        "id": "6e8ae3b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91446b5a-c779-486a-d0bb-e874fd2dde52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 7\n",
        "\n",
        "# Use the scikit-learn MissingIndicator function to create a new column in the Soybean data frame which \n",
        "# is a indicator variable identifying rows where the column sever contains a missing value\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.impute import MissingIndicator\n",
        "\n",
        "ind = MissingIndicator()\n",
        "ind.fit(Soybean.loc[:,['sever']])\n",
        "ind.transform(Soybean.loc[:,['sever']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbbd9321",
      "metadata": {
        "id": "dbbd9321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "cf4262ab-d275-4979-9913-b6035af0b81b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 8\n",
        "\n",
        "# Use pandas function read_csv to load data from the file 'GermanCredit.csv' into a dataframe named 'data'.\n",
        "# The file can be downloaded from the Week 4 module in Brightspace.\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv('GermanCredit.csv')\n",
        "\n",
        "# Next, write python code to draw a histogram for the variable Amount\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(data['Amount'])\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Amount')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3fdda9",
      "metadata": {
        "id": "0d3fdda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "a13b110b-6592-4fe4-a58c-678f89d60d03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Duration  Amount  InstallmentRatePercentage  ResidenceDuration  Age  \\\n",
              "0         6    1169                          4                  4   67   \n",
              "1        48    5951                          2                  2   22   \n",
              "2        12    2096                          2                  3   49   \n",
              "3        42    7882                          2                  4   45   \n",
              "4        24    4870                          3                  4   53   \n",
              "\n",
              "   NumberExistingCredits  NumberPeopleMaintenance  Telephone  ForeignWorker  \\\n",
              "0                      2                        1          0              1   \n",
              "1                      1                        1          1              1   \n",
              "2                      1                        2          1              1   \n",
              "3                      1                        2          1              1   \n",
              "4                      2                        2          1              1   \n",
              "\n",
              "  Class  ...  OtherInstallmentPlans.Stores  OtherInstallmentPlans.None  \\\n",
              "0  Good  ...                             0                           1   \n",
              "1   Bad  ...                             0                           1   \n",
              "2  Good  ...                             0                           1   \n",
              "3  Good  ...                             0                           1   \n",
              "4   Bad  ...                             0                           1   \n",
              "\n",
              "   Housing.Rent  Housing.Own  Housing.ForFree  Job.UnemployedUnskilled  \\\n",
              "0             0            1                0                        0   \n",
              "1             0            1                0                        0   \n",
              "2             0            1                0                        0   \n",
              "3             0            0                1                        0   \n",
              "4             0            0                1                        0   \n",
              "\n",
              "   Job.UnskilledResident  Job.SkilledEmployee  \\\n",
              "0                      0                    1   \n",
              "1                      0                    1   \n",
              "2                      1                    0   \n",
              "3                      0                    1   \n",
              "4                      0                    1   \n",
              "\n",
              "   Job.Management.SelfEmp.HighlyQualified  SqrtAmount  \n",
              "0                                       0   34.190642  \n",
              "1                                       0   77.142725  \n",
              "2                                       0   45.782093  \n",
              "3                                       0   88.780629  \n",
              "4                                       0   69.785385  \n",
              "\n",
              "[5 rows x 63 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3fdddfb-5901-464e-af5f-b7dcb6ab1bdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Duration</th>\n",
              "      <th>Amount</th>\n",
              "      <th>InstallmentRatePercentage</th>\n",
              "      <th>ResidenceDuration</th>\n",
              "      <th>Age</th>\n",
              "      <th>NumberExistingCredits</th>\n",
              "      <th>NumberPeopleMaintenance</th>\n",
              "      <th>Telephone</th>\n",
              "      <th>ForeignWorker</th>\n",
              "      <th>Class</th>\n",
              "      <th>...</th>\n",
              "      <th>OtherInstallmentPlans.Stores</th>\n",
              "      <th>OtherInstallmentPlans.None</th>\n",
              "      <th>Housing.Rent</th>\n",
              "      <th>Housing.Own</th>\n",
              "      <th>Housing.ForFree</th>\n",
              "      <th>Job.UnemployedUnskilled</th>\n",
              "      <th>Job.UnskilledResident</th>\n",
              "      <th>Job.SkilledEmployee</th>\n",
              "      <th>Job.Management.SelfEmp.HighlyQualified</th>\n",
              "      <th>SqrtAmount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>34.190642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bad</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>77.142725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45.782093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>88.780629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bad</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>69.785385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 63 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3fdddfb-5901-464e-af5f-b7dcb6ab1bdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3fdddfb-5901-464e-af5f-b7dcb6ab1bdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3fdddfb-5901-464e-af5f-b7dcb6ab1bdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 9\n",
        "\n",
        "# Create a new variable in data named 'SqrtAmount' which is equal to the square root of Amount\n",
        "\n",
        "import numpy as np\n",
        "data['SqrtAmount'] = np.sqrt(data[['Amount']].sum(axis=1))\n",
        "data.head() # To make sure the SqrtAmount column shows up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dd1ac2f",
      "metadata": {
        "id": "0dd1ac2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0a4ac5d4-55d0-4685-92e2-4971f90c2a1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 10\n",
        "\n",
        "# Draw a histogram for the variable SqrtAmount. Observe how this transformation\n",
        "# helps offset skewness. The log() transformed may have been used for this \n",
        "# purpose also.\n",
        "\n",
        "plt.hist(data['SqrtAmount'])\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Square Root of Amount')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee3814a",
      "metadata": {
        "scrolled": true,
        "id": "6ee3814a"
      },
      "outputs": [],
      "source": [
        "# 11\n",
        "\n",
        "# Run the following code to prepare data for regression models in scikit-learn by dividing \n",
        "# it into train and test data sets. This model will be used to predict the value of SqrtAmount\n",
        "# based on other fields in the data set.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "y = data['SqrtAmount']\n",
        "X = data.drop(columns=['SqrtAmount', 'Amount'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# Next, Write code below to populate lists called str_vars and num_vars.\n",
        "# The list str_vars should contain a list of column names in X which \n",
        "# are string variables (dtype = 'object'). The list num_vars should contain \n",
        "# a list of column names in data which are numeric.\n",
        "# These will be used in a linear regression model to predict SqrtAmount.\n",
        "\n",
        "# Initialize\n",
        "str_vars = [] # String variables\n",
        "num_vars = [] # Numeric variables\n",
        "\n",
        "for i in X_train.columns:\n",
        "    if X_train.dtypes[i] == 'object':\n",
        "        str_vars.append(i)\n",
        "    else:\n",
        "        num_vars.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bebeab",
      "metadata": {
        "id": "47bebeab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "12dfd776-815d-47be-c9d9-23572d44d058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   minmaxscaler__Duration  minmaxscaler__InstallmentRatePercentage  \\\n",
              "0                0.294118                                 0.333333   \n",
              "1                0.647059                                 0.000000   \n",
              "2                0.117647                                 1.000000   \n",
              "3                0.102941                                 0.000000   \n",
              "4                0.117647                                 1.000000   \n",
              "\n",
              "   minmaxscaler__ResidenceDuration  minmaxscaler__Age  \\\n",
              "0                         0.666667           0.285714   \n",
              "1                         0.000000           0.142857   \n",
              "2                         0.333333           0.178571   \n",
              "3                         0.333333           0.375000   \n",
              "4                         1.000000           0.839286   \n",
              "\n",
              "   minmaxscaler__NumberExistingCredits  minmaxscaler__NumberPeopleMaintenance  \\\n",
              "0                             0.333333                                    0.0   \n",
              "1                             0.000000                                    0.0   \n",
              "2                             0.333333                                    0.0   \n",
              "3                             0.333333                                    1.0   \n",
              "4                             0.333333                                    0.0   \n",
              "\n",
              "   minmaxscaler__Telephone  minmaxscaler__ForeignWorker  \\\n",
              "0                      1.0                          1.0   \n",
              "1                      1.0                          1.0   \n",
              "2                      0.0                          1.0   \n",
              "3                      1.0                          1.0   \n",
              "4                      1.0                          1.0   \n",
              "\n",
              "   minmaxscaler__CheckingAccountStatus.lt.0  \\\n",
              "0                                       0.0   \n",
              "1                                       0.0   \n",
              "2                                       0.0   \n",
              "3                                       1.0   \n",
              "4                                       1.0   \n",
              "\n",
              "   minmaxscaler__CheckingAccountStatus.0.to.200  ...  \\\n",
              "0                                           0.0  ...   \n",
              "1                                           0.0  ...   \n",
              "2                                           0.0  ...   \n",
              "3                                           0.0  ...   \n",
              "4                                           0.0  ...   \n",
              "\n",
              "   minmaxscaler__OtherInstallmentPlans.None  minmaxscaler__Housing.Rent  \\\n",
              "0                                       1.0                         0.0   \n",
              "1                                       0.0                         0.0   \n",
              "2                                       1.0                         0.0   \n",
              "3                                       1.0                         0.0   \n",
              "4                                       1.0                         0.0   \n",
              "\n",
              "   minmaxscaler__Housing.Own  minmaxscaler__Housing.ForFree  \\\n",
              "0                        1.0                            0.0   \n",
              "1                        1.0                            0.0   \n",
              "2                        1.0                            0.0   \n",
              "3                        1.0                            0.0   \n",
              "4                        0.0                            1.0   \n",
              "\n",
              "   minmaxscaler__Job.UnemployedUnskilled  minmaxscaler__Job.UnskilledResident  \\\n",
              "0                                    0.0                                  0.0   \n",
              "1                                    0.0                                  0.0   \n",
              "2                                    0.0                                  0.0   \n",
              "3                                    0.0                                  1.0   \n",
              "4                                    0.0                                  0.0   \n",
              "\n",
              "   minmaxscaler__Job.SkilledEmployee  \\\n",
              "0                                1.0   \n",
              "1                                1.0   \n",
              "2                                0.0   \n",
              "3                                0.0   \n",
              "4                                0.0   \n",
              "\n",
              "   minmaxscaler__Job.Management.SelfEmp.HighlyQualified  \\\n",
              "0                                                0.0      \n",
              "1                                                0.0      \n",
              "2                                                1.0      \n",
              "3                                                0.0      \n",
              "4                                                1.0      \n",
              "\n",
              "   onehotencoder__Class_Bad  onehotencoder__Class_Good  \n",
              "0                       0.0                        1.0  \n",
              "1                       0.0                        1.0  \n",
              "2                       0.0                        1.0  \n",
              "3                       0.0                        1.0  \n",
              "4                       0.0                        1.0  \n",
              "\n",
              "[5 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7d42e5b-b311-4956-8b47-a43049aff0f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>minmaxscaler__Duration</th>\n",
              "      <th>minmaxscaler__InstallmentRatePercentage</th>\n",
              "      <th>minmaxscaler__ResidenceDuration</th>\n",
              "      <th>minmaxscaler__Age</th>\n",
              "      <th>minmaxscaler__NumberExistingCredits</th>\n",
              "      <th>minmaxscaler__NumberPeopleMaintenance</th>\n",
              "      <th>minmaxscaler__Telephone</th>\n",
              "      <th>minmaxscaler__ForeignWorker</th>\n",
              "      <th>minmaxscaler__CheckingAccountStatus.lt.0</th>\n",
              "      <th>minmaxscaler__CheckingAccountStatus.0.to.200</th>\n",
              "      <th>...</th>\n",
              "      <th>minmaxscaler__OtherInstallmentPlans.None</th>\n",
              "      <th>minmaxscaler__Housing.Rent</th>\n",
              "      <th>minmaxscaler__Housing.Own</th>\n",
              "      <th>minmaxscaler__Housing.ForFree</th>\n",
              "      <th>minmaxscaler__Job.UnemployedUnskilled</th>\n",
              "      <th>minmaxscaler__Job.UnskilledResident</th>\n",
              "      <th>minmaxscaler__Job.SkilledEmployee</th>\n",
              "      <th>minmaxscaler__Job.Management.SelfEmp.HighlyQualified</th>\n",
              "      <th>onehotencoder__Class_Bad</th>\n",
              "      <th>onehotencoder__Class_Good</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.117647</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.102941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.117647</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.839286</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7d42e5b-b311-4956-8b47-a43049aff0f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7d42e5b-b311-4956-8b47-a43049aff0f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7d42e5b-b311-4956-8b47-a43049aff0f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# 12\n",
        "\n",
        "# Use a column transformer to update X_train so that string variables become one-hot-encoded and\n",
        "# numeric values are standardized to have a minimum value of zero and maximum value of one. Use the\n",
        "# MinMaxScaler() function in scikit-learn to do this. Examine documentation if needed. After \n",
        "# transformation, X_train should be a dataframe containing the transformed data with column names \n",
        "# defined by the get_feature_names_out() function of the column transformer.\n",
        "\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), num_vars),\n",
        "    (OneHotEncoder(sparse=False), str_vars)\n",
        ")\n",
        "\n",
        "ct.fit(X_train)\n",
        "X_train = pd.DataFrame(ct.transform(X_train), columns=ct.get_feature_names_out())\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eaff2e8",
      "metadata": {
        "scrolled": false,
        "id": "4eaff2e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "4ba2e7ac-df46-45eb-a189-9fde44bd50a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.04929876, 0.02089357, 0.04828477, 0.03268623, 0.02413011]),\n",
              " 'score_time': array([0.01120186, 0.01425767, 0.02953815, 0.02111173, 0.01571345]),\n",
              " 'test_score': array([0.67454903, 0.5233799 , 0.63611711, 0.57644712, 0.58008547]),\n",
              " 'train_score': array([0.65965166, 0.68501995, 0.6733412 , 0.6841463 , 0.68374323])}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validation scores with alpha = 0.001: 0.598\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.01778173, 0.03069425, 0.02369356, 0.01154327, 0.02696633]),\n",
              " 'score_time': array([0.01528239, 0.01392174, 0.01525664, 0.00648022, 0.02062488]),\n",
              " 'test_score': array([0.67452058, 0.52351509, 0.63608583, 0.57650288, 0.58010603]),\n",
              " 'train_score': array([0.65965153, 0.68501983, 0.67334109, 0.68414616, 0.68374309])}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validation scores with alpha = 0.01: 0.598\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.02037859, 0.01383042, 0.00541425, 0.00488186, 0.00537872]),\n",
              " 'score_time': array([0.00357437, 0.0034101 , 0.01161742, 0.003196  , 0.00622916]),\n",
              " 'test_score': array([0.67422289, 0.52484012, 0.63576512, 0.57704364, 0.58029194]),\n",
              " 'train_score': array([0.65963893, 0.68500711, 0.67332963, 0.68413303, 0.68372997])}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validation scores with alpha = 0.1: 0.598\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.01782584, 0.01101613, 0.00966358, 0.01890588, 0.00639725]),\n",
              " 'score_time': array([0.0031929 , 0.00346828, 0.00899625, 0.00323367, 0.01053309]),\n",
              " 'test_score': array([0.6701438 , 0.53573033, 0.63189649, 0.58097404, 0.58051251]),\n",
              " 'train_score': array([0.65854504, 0.68389342, 0.67232266, 0.68298319, 0.68259383])}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validation scores with alpha = 1: 0.600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.01249337, 0.02806115, 0.01241016, 0.02851129, 0.01149058]),\n",
              " 'score_time': array([0.0031631 , 0.00952148, 0.00303459, 0.00550508, 0.00314093]),\n",
              " 'test_score': array([0.60399654, 0.55160707, 0.57798451, 0.56528756, 0.53720304]),\n",
              " 'train_score': array([0.61844131, 0.64119353, 0.63326054, 0.63902997, 0.64105164])}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validation scores with alpha = 10: 0.567\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.00551176, 0.00464368, 0.01261735, 0.0116365 , 0.01151848]),\n",
              " 'score_time': array([0.00708556, 0.00563669, 0.0067234 , 0.00679326, 0.01018405]),\n",
              " 'test_score': array([0.36747265, 0.40333676, 0.37860304, 0.38268314, 0.34481509]),\n",
              " 'train_score': array([0.42183902, 0.42132228, 0.42755223, 0.42004688, 0.43465536])}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validation scores with alpha = 100: 0.375\n"
          ]
        }
      ],
      "source": [
        "# 13\n",
        "\n",
        "# Use the transformed X_train dataset with k-fold cross-validation to train a Ridge regression\n",
        "# model for several values of alpha (0.001, .01, .1, 1, 10, 100). Which alpha value gives the \n",
        "# best cross-validation score?\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn import linear_model\n",
        "\n",
        "for i in [.001, .01, .1, 1, 10, 100]:\n",
        "    regr = linear_model.Ridge(alpha=i)\n",
        "    \n",
        "    kfold = KFold(n_splits=5)\n",
        "    \n",
        "    res = cross_validate(regr, X_train, y_train, cv=5, return_train_score=True)\n",
        "    display(res)\n",
        "    summary = cross_val_score(regr, X_train, y_train, cv=kfold)\n",
        "    print(\"Mean cross-validation scores with alpha = {}: {:.3f}\".format(i, summary.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3aa6bce",
      "metadata": {
        "id": "c3aa6bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "e5477406-44df-41d4-d6ed-e566ad0314ba"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2e64e20b11a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
          ]
        }
      ],
      "source": [
        "# 14\n",
        "\n",
        "# Use the transformed X_train dataset with k-fold cross-validation to train a Lasso regression\n",
        "# model for several values of alpha (0.001, .01, .1, 1, 10, 100). Which alpha value gives the \n",
        "# best cross-validation score?\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "for i in [.001, .01, .1, 1, 10, 100]:\n",
        "    regr = linear_model.Lasso(alpha=i)\n",
        "    \n",
        "    kfold = KFold(n_splits=5)\n",
        "    \n",
        "    res = cross_validate(regr, X_train, y_train, cv=5, return_train_score=True)\n",
        "    display(res)\n",
        "    summary = cross_val_score(regr, X_train, y_train, cv=kfold)\n",
        "    print(\"Mean cross-validation scores with alpha = {}: {:.3f}\".format(i, summary.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9aa140",
      "metadata": {
        "id": "8d9aa140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "ab595bf6-6640-4adf-ca5d-d316bac31260"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ee50e5d1c358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the train and test set scores resulting from the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Now we need to train the model on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
          ]
        }
      ],
      "source": [
        "# 15 \n",
        "\n",
        "# Using the optimal value of alpha for lasso regression found in the previous exercies,\n",
        "# train the model on the entire X_train data set and test it with the X_test data set.\n",
        "# Print the train and test set scores resulting from the model.\n",
        "\n",
        "regr = linear_model.Lasso(alpha=.1)\n",
        "\n",
        "#Now we need to train the model on the training set\n",
        "regr.fit(X_train,y_train)\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(regr.score(X_train, y_train)))\n",
        "\n",
        "#X_test = pd.DataFrame(imp.fit_transform(X_test), columns=imp.get_feature_names_out())\n",
        "X_test = pd.DataFrame(ct.transform(X_test), columns=ct.get_feature_names_out())\n",
        "print(\"Test set score: {:.3f}\".format(regr.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b13463",
      "metadata": {
        "id": "06b13463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "89b697fa-63a5-4650-b6b8-106d83cb743c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7c34f6995877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# the nonzero coefficents along with the variables names to which they correspond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnonzero_coef_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnonzero_coef_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'const'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'regr' is not defined"
          ]
        }
      ],
      "source": [
        "# 16\n",
        "\n",
        "# Inspect the coefficients of the lasso model trained in the previous step and print\n",
        "# the nonzero coefficents along with the variables names to which they correspond\n",
        "nonzero_coef_dict = {}\n",
        "nonzero_coef_dict['const'] = regr.intercept_\n",
        "k = 0\n",
        "for i in regr.feature_names_in_:\n",
        "    if regr.coef_[k] != 0:\n",
        "        nonzero_coef_dict[i] = regr.coef_[k]\n",
        "    k += 1\n",
        "print(nonzero_coef_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed05a168",
      "metadata": {
        "scrolled": false,
        "id": "ed05a168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "464281de-5ece-4ac4-fb5e-3cbae7ef03dc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9de073296f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Simple Linear Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'regr' is not defined"
          ]
        }
      ],
      "source": [
        "# 17\n",
        "\n",
        "# Create a scatter plot of Actual SqrtAmount versus Predicted SqrtAmount\n",
        "# including both the train and test data sets. Color the points from the\n",
        "# train set blue and the points from the test set red. Include a legend\n",
        "# the graph.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_train_pred = regr.predict(X_train)\n",
        "y_test_pred = regr.predict(X_test)\n",
        "# Simple Linear Regression\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_train_pred, y_train, s=8, alpha=0.5, label='train')\n",
        "plt.scatter(y_test_pred, y_test, s=8, alpha=0.5, c='red', label='test')\n",
        "plt.xlabel('Predicted Yield')\n",
        "plt.ylabel('Actual Yield')\n",
        "plt.title('Scatter Plot')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}